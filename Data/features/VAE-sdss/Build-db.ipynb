{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import SpecReader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sdss (VAE) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/'\n",
    "keys_path = '../../sdss/VAE-dataset/keys.csv'\n",
    "spec_dir = '../../sdss/VAE-dataset/spectra/'\n",
    "spec_save = root+'specs.npy'\n",
    "train_save = root+'specs-train.npy'\n",
    "test_save = root+'specs-test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_csv(keys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(root):\n",
    "    os.makedirs(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(names, keys):\n",
    "    names = [name.split('/')[-1].rstrip('.fits').split(\"-\")[1:] for name in names]\n",
    "    labels = []\n",
    "    for key in tqdm(names):\n",
    "        cond = keys['plate'].isin([key[0]]) \n",
    "        cond = cond & keys['mjd'].isin([key[1]])\n",
    "        cond = cond & keys['fiberid'].isin([key[2]])\n",
    "        subclass = keys.loc[cond]['subclass'].values\n",
    "        labels.append(subclass)\n",
    "        \n",
    "    labels = np.array(list(map(lambda x: x[0][0], labels)))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_db(spec_dir, keys_path):\n",
    "    assert os.path.exists(keys_path)\n",
    "    \n",
    "    spec_reader = SpecReader(root = root)\n",
    "    spec_reader.build_db(spec_dir,\n",
    "                         n_specs=-1,\n",
    "                         normed=True,\n",
    "                         down_sample=True,)\n",
    "\n",
    "    # All wave lengths equal\n",
    "    assert (spec_reader.wlen == spec_reader.wlen[0]).all()\n",
    "    \n",
    "    keys = pd.read_csv(keys_path)\n",
    "    labels = get_labels(spec_reader.names, keys)\n",
    "    db = {'flux':spec_reader.flux, \n",
    "          'wlen_same': spec_reader.wlen_same, \n",
    "          'names': spec_reader.names, \n",
    "          'labels': labels}\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20949/20949 [02:56<00:00, 118.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read:  177.31545090675354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20602/20602 [00:00<00:00, 73315.45it/s]\n",
      "100%|██████████| 20602/20602 [00:09<00:00, 2181.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to down sample:  12.478596925735474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20602/20602 [00:39<00:00, 525.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20602, 3794), (3794,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = build_db(spec_dir, keys_path)\n",
    "np.save(spec_save, db)\n",
    "db['flux'].shape, db['wlen_same'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20602, 20950, 348, 0.016610978520286368)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of dropped spectra\n",
    "spec_files = os.listdir(spec_dir)\n",
    "spec_N = len(spec_files)\n",
    "db_N = db['labels'].shape[0]\n",
    "db_N, spec_N, spec_N - db_N, 1-db_N/spec_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_save(spec_save, train_save, test_save):\n",
    "    db = np.load(spec_save).item()\n",
    "    data = list(zip(db['flux'], db['labels'], db['names']))\n",
    "    wlen_same = db['wlen_same']\n",
    "\n",
    "    train, test = train_test_split(data, shuffle=True, test_size=0.1)\n",
    "\n",
    "    train = list(map(np.array, zip(*train)))\n",
    "    db_train = dict(zip(['flux', 'labels','names'], train))\n",
    "    db_train['wlen_same'] = wlen_same\n",
    "\n",
    "    test = list(map(np.array, zip(*test)))\n",
    "    db_test = dict(zip(['flux', 'labels','names'], test))\n",
    "    db_test['wlen_same'] = wlen_same\n",
    "\n",
    "    np.save(train_save, db_train)\n",
    "    np.save(test_save, db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save(spec_save, train_save, test_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### css-sdss dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = './data/params.npy'\n",
    "keys_path_x = '../../css-sdss/X-match/keys.csv'\n",
    "spec_dir_x = '../../css-sdss/spectra/'\n",
    "spec_save_x = root+'specs-x-match.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_x(name, keys):\n",
    "    name = name.split('/')[-1]\n",
    "    label =  keys.loc[keys['sloan_file']==name]['label']\n",
    "    if len(label)==0:\n",
    "        print(name)\n",
    "        return None\n",
    "    return label.values[0]\n",
    "\n",
    "def build_db_x(spec_dir, keys_path, w_min, w_max):\n",
    "    spec_reader_x = SpecReader(root = root)\n",
    "    spec_reader_x.build_db(spec_dir,\n",
    "                           n_specs=-1,\n",
    "                           normed=True,\n",
    "                           down_sample=True,\n",
    "                           threshold=[w_min, w_max])\n",
    "    \n",
    "    keys = pd.read_csv(keys_path)\n",
    "    label_fn = lambda name: get_labels_x(name, keys)\n",
    "    labels = np.array(list(map(label_fn, spec_reader_x.names)))\n",
    "    db = {'flux':spec_reader_x.flux, \n",
    "          'wlen_same': spec_reader_x.wlen_same, \n",
    "          'names': spec_reader_x.names, \n",
    "          'labels': labels}\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3296/3296 [00:25<00:00, 127.54it/s]\n",
      "100%|██████████| 3228/3228 [00:00<00:00, 83951.10it/s]\n",
      " 35%|███▌      | 1132/3228 [00:00<00:00, 8934.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read:  26.214890956878662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3228/3228 [00:00<00:00, 7985.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to down sample:  1.6185717582702637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3228, 3794), (3794,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.load(param_path).item()\n",
    "w_min = params['w_min']\n",
    "w_max = params['w_max']\n",
    "db_x = build_db_x(spec_dir_x, keys_path_x, w_min, w_max)\n",
    "np.save(spec_save_x, db_x)\n",
    "db_x['flux'].shape, db_x['wlen_same'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
